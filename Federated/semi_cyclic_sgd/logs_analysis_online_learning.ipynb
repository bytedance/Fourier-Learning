{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "A6Cf6EtZ0zX3"
      },
      "outputs": [],
      "source": [
        "# Copyright 2019, The TensorFlow Federated Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"\n",
        "Note: This file may have been modified by ByteDance Inc.\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import sys\n",
        "from IPython import display\n",
        "\n",
        "if not sys.version_info >= (3, 0):\n",
        "  sys.stdout.write(\"This notebook requires Python 3.x\\n\")\n",
        "  sys.exit(1)\n",
        "\n",
        "# Set this to the directory where logs from your experiments reside.\n",
        "LOG_DIR=\"/tmp/sc_paper/logs\"\n",
        "\n",
        "def set_matplotlib_params(font_size=8, params=None):\n",
        "  \"\"\"Resets matplotlib defaults to nicer defaults, esp. for publications.\n",
        "\n",
        "  Args:\n",
        "    font_size: Default font size.\n",
        "    params: A dict of other params to update, e.g. {'figure.figsize': [7, 5]}.\n",
        "  \"\"\"\n",
        "  matplotlib.rcdefaults()\n",
        "\n",
        "  # Define our own defaults:\n",
        "  default_params = {\n",
        "      'axes.labelsize': font_size,\n",
        "      'axes.titlesize': font_size,\n",
        "      'font.size': font_size,\n",
        "      'legend.fontsize': font_size,\n",
        "      'xtick.labelsize': font_size,\n",
        "      'ytick.labelsize': font_size,\n",
        "      'font.family': 'sans-serif',\n",
        "      'pdf.fonttype': 42,  # Avoid Type 3 fonts in publication plots\n",
        "      'ps.fonttype': 42,  # Avoid Type 3 fonts in publication plots\n",
        "      'legend.frameon': False,\n",
        "  }\n",
        "  if params:\n",
        "    default_params.update(params)\n",
        "  matplotlib.rcParams.update(default_params)\n",
        "\n",
        "set_matplotlib_params(10,\n",
        "    {'legend.handlelength': 3.0,\n",
        "     'figure.figsize': [6, 4],  \n",
        "     'lines.linewidth': 1.5,\n",
        "    })\n",
        "\n",
        "def get_mean_and_std(x): # x is a list of lists\n",
        "  \"\"\"Computes mean and std vectors from matrices.\n",
        "  \n",
        "  Args:\n",
        "    x: a list of lists of numbers. Inner lists must have same lengths.\n",
        "  \n",
        "  Returns:\n",
        "    A dictionary with entries 'mean' and 'std', containing lists of the mean\n",
        "    values and standard deviations, computed along axis 0.\n",
        "  \"\"\"  \n",
        "  return {'mean': np.mean(x, axis=0).tolist(), 'std': np.std(x, axis=0).tolist()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "l22jsUBf02AH"
      },
      "outputs": [],
      "source": [
        "def find_key_val(lines, key, num_results=1):\n",
        "  \"\"\"Get \"key=value\" values from a list of lines.\n",
        "  \n",
        "  Args:\n",
        "    lines: a list of strings containing key=value pairs\n",
        "    key: a string key to search for in key=value expressions\n",
        "    num_results: Expected number of results. This function fails if less or more\n",
        "      lines starting with \"key=\" are found\n",
        "  \"\"\"\n",
        "  lines = [l for l in lines if l.startswith(key)]    \n",
        "  assert(len(lines) == num_results)\n",
        "  if num_results == 1:\n",
        "    return lines[0].lstrip(key)\n",
        "  else:\n",
        "    return [l.lstrip(prefix) for l  in lines]\n",
        "\n",
        "def parse_logfile(f, results, abort_function):\n",
        "  \"\"\"Parses a log file from an experiment run.\n",
        "  \n",
        "  Args:\n",
        "    f: log file path\n",
        "    results: existing dictionary where results will be stored. See below for\n",
        "      details on the contents of this dictionary.\n",
        "    abort_function: function that takes the log file contents as list of lines\n",
        "      and returns true if this file - based on the contents - should be ignored.\n",
        "      This can be used to filter out files that do not match certain criteria,\n",
        "      e.g. log files that do not contain a certain configuration such as\n",
        "      \"bias=0.5\".\n",
        "      \n",
        "  Returns:\n",
        "    A new entry in results, stored in results[replica], where replica is the\n",
        "    replica number extraced from the log file. Any configuration is run\n",
        "    num_replica times, and the i-th such replica will store \"replica=i\" in the\n",
        "    log file. The contents are log file dependent:\n",
        "      \n",
        "    results[replica][learning_rate][mode]\n",
        "    for mode==iid:\n",
        "      results[learning_rate][mode]['avg'] = [...]\n",
        "      results[learning_rate][mode]['raw'][test_group] = [...]\n",
        "    for mode==sep:\n",
        "      results[learning_rate][mode]['avg'] = [...]\n",
        "      results[learning_rate][mode]['raw'][train_group][test_group] = [...]\n",
        "    for mode==sc:\n",
        "      results[learning_rate][mode]['sc']: [...] average over matrix\n",
        "      results[learning_rate][mode]['pl']: [...] average over matrix diagonal\n",
        "      results[learning_rate][mode]['raw'][train_group][test_group] = [...]\n",
        "    # Yingxiang add fourier mode\n",
        "    for mode==fourier:\n",
        "      results[learning_rate][mode]['fourier']: [...] average over matrix\n",
        "  \"\"\"\n",
        "      \n",
        "  def get_losses(lines, num_groups, num_examples_per_day_per_group):\n",
        "    \"\"\"Extracts losses and corresponding #examples from logs. Ignore epochs.\"\"\"\n",
        "    num_examples=[[] for i in range(0, num_groups)]\n",
        "    losses=[[] for i in range(0, num_groups)]\n",
        "    r = r'^day (\\d+), group (\\d+): trained on (\\d+) examples, loss=([\\d.]+)$'\n",
        "    for l in lines:\n",
        "      m = re.search(r, l)\n",
        "      if m:\n",
        "        day = int(m.group(1))\n",
        "        group = int(m.group(2))\n",
        "        num_examples[group].append(int(day)*num_examples_per_day_per_group+int(m.group(3)))\n",
        "        losses[group].append(float(m.group(3)))\n",
        "    return num_examples, losses\n",
        "\n",
        "  def get_sc_accuracies(lines, num_groups, num_days, num_examples_per_day):    \n",
        "    num_examples_per_day_per_group = num_examples_per_day / num_days\n",
        "    accuracies={}\n",
        "    r = r' (\\d+) on (\\d+): day (\\d+), group (\\d+): num_train_examples (\\d+) \\(dt=\\d+s\\): num correct: \\d+/\\d+ \\(([\\d.]+)\\)$'\n",
        "    for l in lines:\n",
        "      m=re.search(r, l)\n",
        "      if m:\n",
        "        train_group = int(m.group(1))\n",
        "        test_group = int(m.group(2))\n",
        "        day = int(m.group(3))\n",
        "        assert test_group == int(m.group(4))\n",
        "        accuracy = float(m.group(6))\n",
        "        if not train_group in accuracies:\n",
        "          accuracies[train_group] = {}\n",
        "        if not test_group in accuracies[train_group]:\n",
        "          accuracies[train_group][test_group] = {}\n",
        "        accuracies[train_group][test_group][day] = accuracy\n",
        "    res = {'raw': {}}\n",
        "    for trg in accuracies:\n",
        "      res['raw'][trg] = {}\n",
        "      for tsg in accuracies[trg]:\n",
        "        res['raw'][trg][tsg] = [accuracies[trg][tsg][d] for d in accuracies[trg][tsg]]\n",
        "    res['pl'] = [np.mean([accuracies[g][g][d] for g in range(num_groups)]) for d in range(num_days)]\n",
        "\n",
        "    return res\n",
        "\n",
        "  def get_oco_accuracies(lines, num_groups, num_days, num_examples_per_day):    \n",
        "    num_examples_per_day_per_group = num_examples_per_day / num_days\n",
        "    accuracies={}\n",
        "    r = r'oco (\\d+) on (\\d+): day (\\d+), group (\\d+): num_train_examples (\\d+) \\(dt=\\d+s\\): num correct: \\d+/\\d+ \\(([\\d.]+)\\)$'\n",
        "    for l in lines:\n",
        "      m=re.search(r, l)\n",
        "      if m:\n",
        "        train_group = int(m.group(1))\n",
        "        test_group = int(m.group(2))\n",
        "        day = int(m.group(3))\n",
        "        assert test_group == int(m.group(4))\n",
        "        accuracy = float(m.group(6))\n",
        "        if not train_group in accuracies:\n",
        "          accuracies[train_group] = {}\n",
        "        if not test_group in accuracies[train_group]:\n",
        "          accuracies[train_group][test_group] = {}\n",
        "        accuracies[train_group][test_group][day] = accuracy\n",
        "    res = {'raw': {}}\n",
        "    for trg in accuracies:\n",
        "      res['raw'][trg] = {}\n",
        "      for tsg in accuracies[trg]:\n",
        "        res['raw'][trg][tsg] = [accuracies[trg][tsg][d] for d in accuracies[trg][tsg]]\n",
        "    res['pl'] = [np.mean([accuracies[g][g][d] for g in range(num_groups)]) for d in range(num_days)]\n",
        "    return res\n",
        "\n",
        "  def get_sep_accuracies(lines, num_groups, num_days, num_examples_per_day):    \n",
        "    num_examples_per_day_per_group = num_examples_per_day / num_days\n",
        "    accuracies={}\n",
        "    r = r'sep (\\d+) on (\\d+): day (\\d+), group (\\d+): num_train_examples (\\d+) \\(dt=\\d+s\\): num correct: \\d+/\\d+ \\(([\\d.]+)\\)$'\n",
        "    for l in lines:\n",
        "      m=re.search(r, l)\n",
        "      if m:\n",
        "        train_group = int(m.group(1))\n",
        "        test_group = int(m.group(2))\n",
        "        day = int(m.group(3))\n",
        "        assert test_group == int(m.group(4))\n",
        "        accuracy = float(m.group(6))\n",
        "        if not train_group in accuracies:\n",
        "          accuracies[train_group] = {}\n",
        "        if not test_group in accuracies[train_group]:\n",
        "          accuracies[train_group][test_group] = {}\n",
        "        accuracies[train_group][test_group][day] = accuracy        \n",
        "    res = {'raw': {}}\n",
        "    for trg in accuracies:\n",
        "      res['raw'][trg] = {}\n",
        "      for tsg in accuracies[trg]:\n",
        "        res['raw'][trg][tsg] = [accuracies[trg][tsg][d] for d in accuracies[trg][tsg]]\n",
        "    res['avg'] = [np.mean([accuracies[g][g][d] for g in range(num_groups)]) for d in range(num_days)]\n",
        "    return res\n",
        "\n",
        "  # Open the log file, check for integrity, and extract the configuration from\n",
        "  # this run (learning rate, replica number, etc.).\n",
        "  with open(f) as f:\n",
        "    lines = [l.rstrip('\\n') for l in f]\n",
        "  assert lines[-1] == 'END_MARKER'\n",
        "  if abort_function(lines):\n",
        "    return\n",
        "  learning_rate=float(find_key_val(lines, 'lr='))\n",
        "  vocab_size=int(find_key_val(lines, 'vocab_size='))\n",
        "  mode=find_key_val(lines, 'mode=')\n",
        "  num_examples_per_day=int(find_key_val(lines, 'num_train_examples_per_day='))\n",
        "  num_days=int(find_key_val(lines, 'num_days='))\n",
        "  num_groups=int(find_key_val(lines, 'num_groups='))\n",
        "  replica=int(find_key_val(lines, 'replica='))\n",
        "  batch_size=int(find_key_val(lines, 'batch_size='))\n",
        "\n",
        "  def get_fourier_accuracies(lines, num_groups, num_days, num_examples_per_day):    \n",
        "    num_examples_per_day_per_group = num_examples_per_day / num_days\n",
        "    accuracies={}\n",
        "    r = r'fourier (\\d+) on (\\d+): day (\\d+), group (\\d+): num_train_examples (\\d+) \\(dt=\\d+s\\): num correct: \\d+/\\d+ \\(([\\d.]+)\\)$'\n",
        "    for l in lines:\n",
        "      m=re.search(r, l)\n",
        "      if m:\n",
        "        train_group = int(m.group(1))\n",
        "        test_group = int(m.group(2))\n",
        "        day = int(m.group(3))\n",
        "        assert test_group == int(m.group(4))\n",
        "        accuracy = float(m.group(6))\n",
        "        if not train_group in accuracies:\n",
        "          accuracies[train_group] = {}\n",
        "        if not test_group in accuracies[train_group]:\n",
        "          accuracies[train_group][test_group] = {}\n",
        "        accuracies[train_group][test_group][day] = accuracy\n",
        "    res = {'raw': {}}\n",
        "    for trg in accuracies:\n",
        "      res['raw'][trg] = {}\n",
        "      for tsg in accuracies[trg]:\n",
        "        res['raw'][trg][tsg] = [accuracies[trg][tsg][d] for d in accuracies[trg][tsg]]\n",
        "    res['pl'] = [np.mean([accuracies[g][g][d] for g in range(num_groups)]) for d in range(num_days)]\n",
        "    return res\n",
        "\n",
        "  def get_tod_accuracies(lines, num_groups, num_days, num_examples_per_day):    \n",
        "    num_examples_per_day_per_group = num_examples_per_day / num_days\n",
        "    accuracies={}\n",
        "    r = r'time (\\d+) on (\\d+): day (\\d+), group (\\d+): num_train_examples (\\d+) \\(dt=\\d+s\\): num correct: \\d+/\\d+ \\(([\\d.]+)\\)$'\n",
        "    for l in lines:\n",
        "      m=re.search(r, l)\n",
        "      if m:\n",
        "        train_group = int(m.group(1))\n",
        "        test_group = int(m.group(2))\n",
        "        day = int(m.group(3))\n",
        "        assert test_group == int(m.group(4))\n",
        "        accuracy = float(m.group(6))\n",
        "        if not train_group in accuracies:\n",
        "          accuracies[train_group] = {}\n",
        "        if not test_group in accuracies[train_group]:\n",
        "          accuracies[train_group][test_group] = {}\n",
        "        accuracies[train_group][test_group][day] = accuracy\n",
        "    res = {'raw': {}}\n",
        "    for trg in accuracies:\n",
        "      res['raw'][trg] = {}\n",
        "      for tsg in accuracies[trg]:\n",
        "        res['raw'][trg][tsg] = [accuracies[trg][tsg][d] for d in accuracies[trg][tsg]]\n",
        "    res['pl'] = [np.mean([accuracies[g][g][d] for g in range(num_groups)]) for d in range(num_days)]\n",
        "    return res\n",
        "\n",
        "  # Extract the results from this run, depending on what mode was used.\n",
        "  if not replica in results:\n",
        "    results[replica] = {}\n",
        "  if not learning_rate in results[replica]:\n",
        "    results[replica][learning_rate] = {}\n",
        "  if mode == 'pluralistic':\n",
        "    results[replica][learning_rate][mode] = get_sc_accuracies(lines, num_groups, num_days, num_examples_per_day)\n",
        "  elif mode == 'sep':\n",
        "    results[replica][learning_rate][mode] = get_sep_accuracies(lines, num_groups, num_days, num_examples_per_day)\n",
        "  elif mode == 'fourier':\n",
        "    results[replica][learning_rate][mode] = get_fourier_accuracies(lines, num_groups, num_days, num_examples_per_day)\n",
        "  elif mode == 'nline-learning':\n",
        "    mode = 'online-learning'\n",
        "    results[replica][learning_rate][mode] = get_oco_accuracies(lines, num_groups, num_days, num_examples_per_day)\n",
        "  elif mode == 'time-feature':\n",
        "    results[replica][learning_rate][mode] = get_tod_accuracies(lines, num_groups, num_days, num_examples_per_day)\n",
        "  else:\n",
        "    print(mode)\n",
        "    raise ValueError('unknown mode %s' % mode)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mqduhInBCLXM"
      },
      "outputs": [],
      "source": [
        "# Parse log files, plot results.\n",
        "files = [f for f in os.listdir(LOG_DIR) if f.endswith('.log')]\n",
        "# Only use the results from runs that use a data bias of 0.5.\n",
        "for bias in [0.7]:\n",
        "  r = {}\n",
        "  for i, f in enumerate(files):    \n",
        "    parse_logfile(os.path.join(LOG_DIR, f), r, lambda lines: float(find_key_val(lines, 'bias='))!=bias)\n",
        "  # days = range(1, len(r[0][list(r[0].keys())[0]]['iid']['avg']) + 1)\n",
        "  days = range(1, 16)\n",
        "\n",
        "  # Holds results with average and std values from across replicas.\n",
        "  ravg = {}\n",
        "  for lr in sorted(r[0]):\n",
        "    ravg[lr] = {}\n",
        "    ravg[lr]['pluralistic'] = {}\n",
        "    ravg[lr]['pluralistic']['pl'] = get_mean_and_std([r[rep][lr]['pluralistic']['pl'] for rep in r])  # semi-cyclic plurastic-averaging\n",
        "    ravg[lr]['fourier'] = {}\n",
        "    ravg[lr]['fourier']['pl'] = get_mean_and_std([r[rep][lr]['fourier']['pl'] for rep in r])  # align with evaluation method of pluralistic approach\n",
        "    ravg[lr]['oco'] = {}\n",
        "    ravg[lr]['oco']['pl'] = get_mean_and_std([r[rep][lr]['online-learning']['pl'] for rep in r])  # align with evaluation method of pluralistic approach\n",
        "    ravg[lr]['time'] = {}\n",
        "    ravg[lr]['time']['pl'] = get_mean_and_std([r[rep][lr]['time-feature']['pl'] for rep in r])\n",
        "    num_groups = len(r[0][lr]['pluralistic']['raw'])\n",
        "    num_days = len(r[0][lr]['pluralistic']['raw'][0][0])\n",
        "    # plot test accuracy as a function of days, for the four different modes.\n",
        "    plt.figure()\n",
        "    plt.errorbar(days, ravg[lr]['pluralistic']['pl']['mean'], ravg[lr]['pluralistic']['pl']['std'], label='Pluralistic', color='red')\n",
        "    plt.errorbar(days, ravg[lr]['fourier']['pl']['mean'], ravg[lr]['fourier']['pl']['std'], label='Fourier Learning', color='purple')\n",
        "    plt.errorbar(days, ravg[lr]['oco']['pl']['mean'], ravg[lr]['oco']['pl']['std'], label='Online Learning', color='blue')\n",
        "    plt.errorbar(days, ravg[lr]['time']['pl']['mean'], ravg[lr]['time']['pl']['std'], label='Time-Feature', color='orange')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.ylim([0.5, 0.8])\n",
        "    plt.xlabel('Day')\n",
        "    plt.ylabel('Test Accuracy')\n",
        "    plt.grid()\n",
        "    plt.savefig(\"./fig/{lr}.eps\".format(lr=lr))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "OSS Cyclic Analysis",
      "provenance": [
        {
          "file_id": "1G9H-HPriBD77mNj8TtkKmPswc9pKl4Bm",
          "timestamp": 1558029681690
        },
        {
          "file_id": "1TASLN5EpBp7WuIuhgJzNWmVYLQ5gRpii",
          "timestamp": 1557969917344
        },
        {
          "file_id": "1hFbtXvJjSpXv1_F4KOrqqpSo_2_aN_jp",
          "timestamp": 1547529412275
        }
      ],
      "version": "0.3.2"
    },
    "interpreter": {
      "hash": "beb2b2ab90320514a072b76dadef18b1960d53065922146aafc9dc4b1690e204"
    },
    "kernelspec": {
      "display_name": "Python 3.7.7 64-bit ('periodic': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
